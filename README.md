# Real-estate-price-prediction-analysis


# ğŸ  Przewidywanie cen nieruchomoÅ›ci: Regresja Liniowa vs XGBoost

Projekt analityczny porÃ³wnujÄ…cy skutecznoÅ›Ä‡ klasycznych metod statystycznych oraz nowoczesnych algorytmÃ³w uczenia maszynowego w zadaniu wyceny nieruchomoÅ›ci (zbiÃ³r danych Boston Housing).

## ğŸ“‹ O projekcie
Celem projektu byÅ‚o zbudowanie modelu predykcyjnego, ktÃ³ry na podstawie szeregu cech (np. liczba pokoi, przestÄ™pczoÅ›Ä‡ w okolicy, dostÄ™pnoÅ›Ä‡ infrastruktury) oszacuje wartoÅ›Ä‡ rynkowÄ… nieruchomoÅ›ci.

Projekt stanowi czÄ™Å›Ä‡ pracy inÅ¼ynierskiej i kÅ‚adzie duÅ¼y nacisk na:
*   RygorystycznÄ… analizÄ™ statystycznÄ… (badanie wspÃ³Å‚liniowoÅ›ci).
*   Åšwiadomy dobÃ³r cech.
*   OptymalizacjÄ™ hiperparametrÃ³w.

## ğŸ› ï¸ Wykorzystane technologie
*   **Python** (analiza danych)
*   **Pandas / NumPy** (manipulacja danymi)
*   **Scikit-Learn** (Regresja Liniowa, GridSearchCV, metryki)
*   **XGBoost** (zaawansowany model gradient boosting)
*   **Statsmodels** (analiza VIF)
*   **Matplotlib / Seaborn** (wizualizacja danych)

## âš™ï¸ Metodologia (Workflow)

### 1. Eksploracyjna Analiza Danych (EDA)
*   Analiza rozkÅ‚adÃ³w zmiennych.
*   Badanie korelacji (mapa ciepÅ‚a) w celu wstÄ™pnej identyfikacji zaleÅ¼noÅ›ci.

### 2. Selekcja Cech i Eliminacja MultikolinearnoÅ›ci (VIF)
Zastosowano analizÄ™ **VIF (Variance Inflation Factor)** w celu wykrycia zmiennych silnie skorelowanych ze sobÄ… (multikolinearnoÅ›Ä‡), co mogÅ‚oby zaburzyÄ‡ stabilnoÅ›Ä‡ modelu regresji.
*   Zidentyfikowano zmienne o VIF > 5.
*   Iteracyjnie usuniÄ™to zmienne powodujÄ…ce szum informacyjny, co poprawiÅ‚o interpretowalnoÅ›Ä‡ modelu.

### 3. Modelowanie
Zastosowano podejÅ›cie porÃ³wnawcze:
*   **Model Bazowy (Baseline):** Regresja Liniowa (OLS). SÅ‚uÅ¼y jako punkt odniesienia dla bardziej zÅ‚oÅ¼onych metod.
*   **Model Docelowy:** XGBoost Regressor. Algorytm oparty na drzewach decyzyjnych i wzmocnieniu gradientowym.

### 4. Optymalizacja (GridSearchCV)
Dla modelu XGBoost przeprowadzono strojenie hiperparametrÃ³w przy uÅ¼yciu przeszukiwania siatkÄ… (Grid Search) z walidacjÄ… krzyÅ¼owÄ… (Cross-Validation). Optymalizowano parametry takie jak:
*   `learning_rate`
*   `max_depth`
*   `n_estimators`
*   `colsample_bytree`

## ğŸ“Š Wyniki
W ramach projektu przetestowano dwa algorytmy na danych surowych oraz po transformacji logarytmicznej zmiennej docelowej (ceny). PozwoliÅ‚o to sprawdziÄ‡, jak rozkÅ‚ad danych wpÅ‚ywa na rÃ³Å¼ne rodziny modeli.

| Model | Wariant Danych | MSE (Mniej = Lepiej) | RMSE | R2 Score (WiÄ™cej = Lepiej) |
| :--- | :--- | :---: | :---: | :---: |
| **XGBoost** | **Dane Oryginalne** | **9.50** | **3.08** | **0.8705** ğŸ† |
| Regresja Liniowa | Transformacja Log | 19.46 | 4.41 | 0.7346 |
| XGBoost | Transformacja Log | 24.99 | 5.00 | 0.6592 |
| Regresja Liniowa | Dane Oryginalne | 26.47 | 5.14 | 0.6390 |

### ğŸ“ Analiza i Wnioski

1.  **Dominacja XGBoost:** Najlepszy uzyskany wynik to **R2 = 0.87** dla modelu XGBoost na danych oryginalnych. BÅ‚Ä…d Å›redni (RMSE) wynosiÅ‚ tylko ok. **3.08 tys. $**, co jest znaczÄ…cÄ… poprawÄ… wzglÄ™dem modelu bazowego (5.14 tys. $).
2.  **WpÅ‚yw transformacji danych:**
    *   **Dla Regresji Liniowej:** Zastosowanie transformacji logarytmicznej znacznie poprawiÅ‚o wynik (wzrost R2 z 0.64 na 0.73). Potwierdza to teoriÄ™, Å¼e modele liniowe dziaÅ‚ajÄ… lepiej, gdy zmienna celowa ma rozkÅ‚ad zbliÅ¼ony do normalnego (ceny nieruchomoÅ›ci sÄ… naturalnie prawoskoÅ›ne).
    *   **Dla XGBoost:** Transformacja nie przyniosÅ‚a korzyÅ›ci, a wrÄ™cz pogorszyÅ‚a wynik. Wynika to z natury drzew decyzyjnych, ktÃ³re opierajÄ… siÄ™ na progowaniu (split points) i sÄ… inwariantne na monotoniczne przeksztaÅ‚cenia zmiennych. Najlepsze podziaÅ‚y zostaÅ‚y znalezione na danych surowych.

**Ostateczna decyzja:** Do wdroÅ¼enia rekomendowany jest model **XGBoost trenowany na danych oryginalnych**, ze wzglÄ™du na najwyÅ¼szÄ… predykcjÄ™ i najmniejszy bÅ‚Ä…d Å›redniokwadratowy.

## ğŸš€ Jak uruchomiÄ‡ projekt?

1. Sklonuj repozytorium:
   ```bash
   git clone https://github.com/TWOJA-NAZWA-UZYTKOWNIKA/real-estate-price-prediction-analysis.git
   ```
2. Zainstaluj wymagane biblioteki:
   ```bash
   pip install pandas numpy scikit-learn xgboost statsmodels matplotlib seaborn
   ```
3. Uruchom notatnik Jupyter/Colab:
   `Analiza_Boston_Housing.ipynb`

   ```
   *Autor: Oliwier Stecyk*
   ```
